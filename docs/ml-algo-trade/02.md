# 二、市场和基础数据——来源和技术

数据一直是交易的重要驱动力，交易者长期以来一直努力从获取优质信息中获得优势。这些努力至少可以追溯到有传言称，英国在滑铁卢取得胜利的消息传出后，罗斯柴尔德家族（House of Rothschild）从债券购买中获得了丰厚的收益，而这一消息是由鸽子带过英吉利海峡的。

如今，对更快数据访问的投资形成了由领先的**高频交易**（**HFT**公司组成的 Go West 财团，该财团将**芝加哥商品交易所**（**CME**）与东京连接起来。纽约 CME 和**BATS**（**Better Alternative Trading System**）交易所之间的往返延迟已降至接近理论上 8 毫秒的极限，因为交易员竞相利用套利机会。与此同时，监管机构和交易所已开始引入减速带，以减缓交易速度，限制信息获取不均对竞争的不利影响。

传统上，投资者主要依赖**公开市场和基础数据**。例如，通过专有调查创建或获取私人数据集的努力是有限的。传统策略关注股票基本面，并根据报告的金融数据建立金融模型，可能结合行业或宏观数据预测每股收益和股价。或者，他们利用**技术分析**从市场数据中提取信号，使用根据价格和交易量信息计算的指标。

**机器学习**（**ML**算法）有望比人类定义的规则和启发式更有效地利用市场和基础数据，特别是与**备选数据**相结合时，这是下一章的主题。我们将说明如何将从线性模型到**递归神经网络**（**RNNs**）的 ML 算法应用于市场和基础数据，并生成可交易信号。

本章介绍市场和基础数据源，并解释它们如何反映创建它们的环境。**交易环境**的细节不仅对正确解释市场数据很重要，而且对策略的设计和执行以及现实回溯测试模拟的实施也很重要。

我们还演示了如何使用 Python 访问和处理来自各种来源的交易和金融报表数据。

特别是，本章将涵盖以下主题：

*   市场数据如何反映交易环境的结构
*   以分钟频率处理交易和报价数据
*   使用 Nasdaq ITCH 从 tick 数据重构订单簿
*   使用各种类型的条形图汇总勾号数据
*   使用**可扩展业务报告语言**（**XBRL**）编码的电子文件
*   解析并结合市场和基础数据，创建**市盈率**（**市盈率**系列）
*   如何使用 Python 访问各种市场和基础数据源

您可以在 GitHub 存储库的相应目录中找到本章的代码示例以及指向其他资源的链接。笔记本电脑包括图像的彩色版本。

# 市场数据反映了它的环境

市场数据是交易者如何直接或通过中介机构在众多市场之一上下金融工具订单、如何处理订单以及如何通过供需匹配来设定价格的产物。因此，数据反映了交易场所的制度环境，包括管理订单、交易执行和价格形成的规则和法规。全球概况见 Harris（2003），美国市场详情见 Jones（2018）。

算法交易者使用算法（包括 ML）分析买卖订单流以及由此产生的数量和价格统计数据，以提取交易信号，捕捉对需求-供应动态或某些市场参与者行为的洞察。

我们将首先回顾在回溯测试期间影响交易策略模拟的机构特征，然后再开始处理由此类环境（即纳斯达克）创建的实际交易数据。

## 市场微观结构–螺母和螺栓

市场微观结构研究制度环境如何影响交易过程并形成价格发现、买卖价差和报价、日内交易行为和交易成本等结果（Madhavan 2000；2002）。它是金融研究中增长最快的领域之一，受到算法和电子交易快速发展的推动。

如今，对冲基金赞助内部分析师跟踪快速演变的复杂细节，确保以尽可能最佳的市场价格执行，并设计利用市场摩擦的策略。在深入研究交易产生的数据之前，我们将仅简要概述这些关键概念。参考文献中包含了几个非常详细地处理这个主题的来源。

## 如何交易–不同类型的订单

交易者可以下各种类型的买卖订单。一些订单保证立即执行，而另一些订单可能会说明价格阈值或触发执行的其他条件。除非另有规定，订单通常在同一交易日有效。

*市场指令*旨在在到达交易地点后立即执行指令，价格为当时的价格。相反，*限价指令*仅在市场价格高于卖出限价指令的限价或低于买入限价指令的限价时执行。*止损单*反过来，只有当市场价格高于买入止损单的指定价格，或低于卖出单的指定价格时才会激活。*买入止损单*可用于限制卖空损失。止损单也可能有限制。

订单可附加许多其他条件。例如，*全部或无指令*阻止部分执行；只有在指定数量的股票可用且有效期为一天或更长的情况下，才能填写。它们需要特殊处理，市场参与者看不到。*填写或终止订单*也防止部分执行，但如果不立即执行则取消。*立即或取消订单*立即购买或出售数量的可用股份，并取消剩余股份。*未持有订单*允许经纪人决定执行的时间和价格。最后，*开盘/收盘指令*上的市场在开盘或收盘时或接近开盘或收盘时执行。允许部分处决。

## 交易地点——从交易所到暗池

在高度组织和**监管的交易所**或在**场外交易**（**OTC**市场以不同程度的形式进行证券交易。交易所是一个中心市场，买家和卖家分别为最低的要价和最高的出价而竞争。交易所监管机构通常会强制要求上市和报告，以提高透明度，吸引更多交易员和流动性。OTC 市场，如最佳市场（OTCQX）或风险市场（OTCQB），通常具有较低的监管壁垒。因此，它们适用于范围更广的证券，包括债券或**美国存托凭证**（**美国存托凭证**；在外汇市场上市的股票，例如雀巢公司）。

交易所可能依赖双边交易或集中订单驱动系统，根据特定规则匹配所有买卖订单。许多交易所使用中介机构，通过在某些证券上建立市场来提供流动性。这些**中介机构**包括代表自己作为委托人的经销商和代表他人作为代理人进行交易的经纪人。**价格形成**可能通过拍卖发生，例如在**纽约证券交易所**（**纽约证券交易所**）中最高出价和最低出价匹配，或者通过从卖家购买并出售给买家的经销商。

当年，公司要么主要在纽约证券交易所注册和交易，要么在纳斯达克等场外市场交易。在纽约证券交易所，一位唯一的**专业人士**为特定证券的交易提供中介。该专家通过经纪人接收买卖订单，并在中央订单簿中跟踪限额订单。限价订单的执行优先级取决于价格和时间。在限价指令簿中，买入以最低 ask 交易的专业人士的市场指令（卖出以最高出价交易的专业人士的市场指令），在平局的情况下优先考虑较早的限价指令。通过访问中央订单簿中的所有订单，专家可以发布最佳出价、要价，并根据整体买卖不平衡情况设定市场价格。

在纳斯达克，多家**做市商**促成了股票交易。每个交易商向中央报价系统提供其最佳出价和要价，并随时准备以指定价格交易指定数量的股票。交易者会通过他们的经纪人将他们的订单发送给具有最佳报价的做市商。订单竞争使得以公平价格执行订单成为可能。做市商确保了一个公平有序的市场，提供了流动性，并像专业人士一样传播价格，但只能获得传递给他们的订单，而不是整个市场的供求。这种分割可能会给确定公允价值市场价格带来困难。

今天，**交易已经分裂**；除了美国的两个主要交易场所外，还有 13 个以上的交易场所，包括交易所和**另类交易系统**（**ATSs**），如**电子通信网络**（**ECNs**）。每个都向合并磁带报告交易，但延迟不同。更为困难的是，每个场馆的接洽规则都有所不同，有几种不同的定价和排队模式。

下表列出了截至 2018 年 3 月的 12 个月内，包括衍生品在内的各种资产类别的一些大型全球交易所和交易量。通常，少数金融工具占大多数交易：

<colgroup><col> <col> <col> <col> <col> <col></colgroup> 
| 交换 | 股票 |
| 市值（百万美元） | #上市公司 | 数量/天（百万美元） | #股份/天（'000） | #选项/天（'000） |
| 纽约证券交易所 | 23,138,626 | 2,294 | 78,410 | 6,122 | 1,546 |
| 纳斯达克-美国 | 10,375,718 | 2,968 | 65,026 | 7,131 | 2,609 |
| 日本交易所集团公司。 | 6,287,739 | 3,618 | 28,397 | 3,361 | 1. |
| 上海证券交易所 | 5,022,691 | 1,421 | 34,736 | 9,801 |  |
| 泛欧交易所 | 4,649,073 | 1,240 | 9,410 | 836 | 304 |
| 香港交易所与清算 | 4,443,082 | 2,186 | 12,031 | 1,174 | 516 |
| 伦敦证券交易所集团 | 3,986,413 | 2,622 | 10,398 | 1,011 |  |
| 深圳证券交易所 | 3,547,312 | 2,110 | 40,244 | 14,443 |  |
| 德意志交易所 | 2,339,092 | 506 | 7,825 | 475 |  |
| BSE 印度有限公司 | 2,298,179 | 5,439 | 602 | 1,105 |  |
| 印度国家证券交易所 | 2,273,286 | 1,952 | 5,092 | 10,355 |  |
| BATS 全球市场-美国 |  |  |  |  | 1,243 |
| 芝加哥期权交易所 |  |  |  |  | 1,811 |
| 国际证券交易所 |  |  |  |  | 1,204 |

前面提到的自动交易系统包括数十个**暗池**，允许交易员匿名执行。据估计，2017 年它们占美国所有股票交易的 40%，而 2010 年估计为 16%。暗池出现于 20 世纪 80 年代，当时证交会允许经纪人匹配大宗股票的买家和卖家。高频电子交易的兴起和 2007 年美国证券交易委员会指令保护规则（SEC Order Protection rule）旨在通过透明度刺激竞争和降低交易成本，作为**监管国家市场体系**（**Reg NMS**的一部分）推动了暗池的增长，as 交易员旨在避免大型交易的可见性（Mamudi 2017）。Reg NMS 还设立了**全国最佳出价和出价**（**NBBO**委托书），供经纪人将订单发送至提供最佳价格的场馆。

一些自动交易系统被称为暗池，因为它们不像传统交易所那样广播交易前数据，包括交易状态、价格和买卖订单数量。然而，暗池在交易发生后向**金融业监管局**（**FINRA**报告交易信息。因此，在交易执行之后，暗池才有助于价格发现过程，但可以针对第一章中概述的各种高频交易策略提供保护。

在下一节中，我们将看到市场数据如何捕捉交易活动并反映美国市场的制度基础设施。

# 处理高频数据

两类市场数据涵盖了在美国交易所上市的数千家在 Reg NMS 下交易的公司：**合并提要**结合了来自每个交易场所的交易和报价数据，而每个交易所提供**专有产品**提供该特定场地的其他活动信息。

在本节中，我们将首先介绍纳斯达克提供的专有订单流数据，这些数据代表实际的订单流、交易和最终价格，因为它们是逐点发生的。然后，我们将演示如何将以不规则间隔到达的连续数据流正则化为固定持续时间的条形图。最后，我们将介绍 AlgoSeek 的股票分条数据，其中包含合并交易和报价信息。在每种情况下，我们都将说明如何使用 Python 处理数据，以便您可以利用这些数据源进行交易策略。

## 如何使用纳斯达克订单簿数据

**市场数据**的主要来源是订单簿，订单簿全天实时更新，以反映所有交易活动。交易所通常以收费的方式提供实时数据服务；但是，他们可能会免费提供一些历史数据。

在美国，股票市场提供三个级别的报价，即 L1、L2 和 L3 级别，提供越来越精细的信息和能力：

*   **1 级（L1）**：实时买卖价格信息，可从众多在线来源获得。
*   **第 2 级（L2）**：添加特定做市商的买入和卖出价格以及最近交易的规模和时间信息，以便更好地了解给定股票的流动性。
*   **级别 3（L3）**：增加了输入或更改报价、执行订单和确认交易的功能，仅适用于做市商和交易所会员公司。访问 3 级报价允许注册经纪人满足最佳执行要求。

交易活动反映在市场参与者发送的大量关于订单的**信息中。这些消息通常符合用于实时交换证券交易和市场数据的**电子金融信息交换**（**FIX**通信协议或本机交换协议。**

## 与 FIX 协议通信

正如 SWIFT 是后台（例如，在交易结算中）消息传递的消息协议一样，FIX 协议是交易所、银行、经纪人、清算公司和其他市场参与者之间在交易执行之前和期间进行通信的**事实上的消息传递标准**。富达投资（Fidelity Investments）和所罗门兄弟（Salomon Brothers）于 1992 年推出了 FIX，以促进经纪自营商和机构客户之间的电子通信。在此之前，机构客户通过电话交换信息。

在扩展到外汇、固定收益和衍生品市场，并进一步扩展到交易后以支持直通式处理之前，它在全球股票市场上大受欢迎。交易所提供对固定消息的访问，作为实时数据馈送，由算法交易员解析**以跟踪市场活动，例如，识别市场参与者的足迹并预测他们的下一步行动。**

消息序列允许**重建订单簿**。跨多个 Exchange 的事务规模带来了大量（约 10 TB）的非结构化数据，这些数据的处理非常困难，因此可以成为竞争优势的来源。

FIX 协议目前的版本为 5.0，是一个自由开放的标准，拥有大量附属行业专业人士。它是自描述的，就像最近的 XML 一样，底层的**传输控制协议**（**TCP**层支持固定会话。社区不断添加新功能。

该协议支持管道分隔的键值对，以及以及基于**标记的 FIXML**语法。请求服务器登录的示例消息如下所示：

```py
8=FIX.5.0|9=127|35=A|59=theBroker.123456|56=CSERVER|34=1|32=20180117- 08:03:04|57=TRADE|50=any_string|98=2|108=34|141=Y|553=12345|554=passw0rd!|10=131| 
```

Python 中有几个开源修复实现可用于制定和解析修复消息。服务提供商 Interactive Brokers 为自动交易提供了一个基于补丁的**计算机对计算机接口**（**CTCI**）（请参阅 GitHub 存储库中本章的参考资料部分）。

## 纳斯达克 TotalView 瘙痒数据源

虽然 FIX 占据主导市场份额，但交易所也提供本机协议。纳斯达克提供了 TotalView ITCH**直接数据馈送协议**，该协议允许订户**跟踪权益工具的**订单，从配售到执行或取消。

此数据流的历史记录允许重建订单簿，以跟踪特定证券的活动限额订单。订单簿通过列出每个价格点的出价或出价数量，揭示了全天的**市场深度**。它还可以确定负责特定买卖订单的市场参与者，除非这些订单是匿名下达的。市场深度是流动性和大量市场订单的潜在价格影响的关键指标。

除了匹配市场和限价指令外，纳斯达克还进行**拍卖或交叉**，在开盘和收盘时执行大量交易。随着被动投资持续增长，交易者寻找机会执行更大的股票组合，交叉变得越来越重要。TotalView 还为纳斯达克开盘和收盘交叉以及纳斯达克 IPO/Halt 交叉传播**净订单不平衡指标**（**NOII**。

### 如何解析二进制顺序消息

ITCH v5.0 规范声明了20 多种与系统事件、股票特征、限额订单的放置和修改以及交易执行相关的消息类型。它还包含关于开盘和收盘交叉前净订单不平衡的信息。

纳斯达克提供了几个月的每日二进制文件样本。本章的 GitHub 存储库包含一个笔记本`parse_itch_order_flow_messages.ipynb`，它演示了如何下载和解析瘙痒消息的示例文件。然后，笔记本`rebuild_nasdaq_order_book.ipynb`继续为任何给定的股票代码重建已执行的交易和订单簿。

下表显示了样本文件日期 2019 年 10 月 30 日的**最常见消息类型**的频率：

<colgroup><col> <col> <col></colgroup> 
| 消息类型 | 订单影响 | 邮件数 |
| A. | 新的未分配限额指令 | 127,214,649 |
| D | 订单取消 | 123,296,742 |
| U | 订单取消并被替换 | 25,513,651 |
| E | 全部或部分执行；同一原始订单可能有多条消息 | 7,316,703 |
| X | 部分取消后修改 | 3,568,735 |
| F | 添加属性订单 | 1,423,908 |
| P | 交易信息（非交叉） | 1,525,363 |
| C | 以不同于初始显示价格的价格全部或部分执行 | 129,729 |
| Q | 跨行业信息 | 17,775 |

对于每条消息，**规范**列出了组件及其各自的长度和数据类型：

<colgroup><col> <col> <col> <col> <col></colgroup> 
| 名称 | 抵消 | 长 | 价值 | 笔记 |
| 消息类型 | 0 | 1. | s | 系统事件消息。 |
| 库存定位 | 1. | 2. | 整数 | 总是 0。 |
| 查询号 | 3. | 2. | 整数 | 纳斯达克内部跟踪号码。 |
| 时间戳 | 5. | 6. | 整数 | 自午夜以来的纳秒数。 |
| 订单参考号 | 11 | 8. | 整数 | 接收时分配给新订单的唯一参考号。 |
| 买入/卖出指标 | 19 | 1. | 阿尔法 | 正在添加的订单类型：B=买入订单，S=卖出订单。 |
| 分享 | 20 | 4. | 整数 | 与添加到账簿中的订单关联的股份总数。 |
| 股票 | 24 | 8. | 阿尔法 | 股票符号，右-填充空格。 |
| 价格 | 32 | 4. | 价格（4） | 新订单的显示价格。现场处理说明见本规范*数据类型*。 |
| 归属 | 36 | 4. | 阿尔法 | 与输入的订单关联的纳斯达克市场参与者标识符。 |

Python 提供了`struct`模块来解析二进制数据，该模块使用格式字符串来标识消息元素，该格式字符串指示规范中规定的`byte`字符串的各个组件的长度和类型。

让我们了解解析交易消息和重建订单簿所需的关键步骤：

1.  瘙痒解析器依赖于文件`message_types.xlsx`中提供的消息规范（详见笔记本`parse_itch_order_flow_messages.ipynb`。它根据`formats`字典

    ```py
    formats = {
        ('integer', 2): 'H',  # int of length 2 => format string 'H'
        ('integer', 4): 'I',
        ('integer', 6): '6s', # int of length 6 => parse as string, 
          convert later
        ('integer', 8): 'Q',
        ('alpha', 1)  : 's',
        ('alpha', 2)  : '2s',
        ('alpha', 4)  : '4s',
        ('alpha', 8)  : '8s',
        ('price_4', 4): 'I',
        ('price_8', 8): 'Q',
    } 
    ```

    组合格式字符串
2.  解析器将消息规范转换为格式字符串和捕获消息内容的命名元组：

    ```py
    # Get ITCH specs and create formatting (type, length) tuples
    specs = pd.read_csv('message_types.csv')
    specs['formats'] = specs[['value', 'length']].apply(tuple, 
                               axis=1).map(formats)
    # Formatting for alpha fields
    alpha_fields = specs[specs.value == 'alpha'].set_index('name')
    alpha_msgs = alpha_fields.groupby('message_type')
    alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}
    alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}
    # Generate message classes as named tuples and format strings
    message_fields, fstring = {}, {}
    for t, message in specs.groupby('message_type'):
        message_fields[t] = namedtuple(typename=t,
                                      field_names=message.name.tolist())
        fstring[t] = '>' + ''.join(message.formats.tolist()) 
    ```

3.  alpha 类型的字段需要进行后处理，如`format_alpha`函数

    ```py
    def format_alpha(mtype, data):
        """Process byte strings of type alpha"""
        for col in alpha_formats.get(mtype).keys():
            if mtype != 'R' and col == 'stock':
                data = data.drop(col, axis=1)
                continue
            data.loc[:, col] = (data.loc[:, col]
                                .str.decode("utf-8")
                                .str.strip())
            if encoding.get(col):
                data.loc[:, col] = data.loc[:, col].map(encoding.get(col))
        return data 
    ```

    中所定义

一天的二进制文件包含价值超过 9GB 的 300000000 条消息。该脚本以快速 HDF5 格式将解析结果以迭代方式附加到文件中，以避免内存限制。（有关 HDF5 格式的更多信息，请参阅本章后面的*熊猫高效数据存储*部分。）

以下（简化）代码处理二进制文件并生成按消息类型存储的解析命令：

```py
with (data_path / file_name).open('rb') as data:
    while True:
        message_size = int.from_bytes(data.read(2), byteorder='big', 
                       signed=False)
        message_type = data.read(1).decode('ascii')
        message_type_counter.update([message_type])
        record = data.read(message_size - 1)
        message = message_fields[message_type]._make(
            unpack(fstring[message_type], record))
        messages[message_type].append(message)

        # deal with system events like market open/close
        if message_type == 'S':
            timestamp = int.from_bytes(message.timestamp, 
                                       byteorder='big')
            if message.event_code.decode('ascii') == 'C': # close
                store_messages(messages)
                break 
```

### 总结所有 8500 只股票的交易活动

不出所料，当天交易的 8500 多只证券中的一小部分占了大部分交易：

```py
with pd.HDFStore(itch_store) as store:
    stocks = store['R'].loc[:, ['stock_locate', 'stock']]
    trades = (store['P'].append(
            store['Q'].rename(columns={'cross_price': 'price'}),
            sort=False).merge(stocks))
trades['value'] = trades.shares.mul(trades.price)
trades['value_share'] = trades.value.div(trades.value.sum())
trade_summary = (trades.groupby('stock').value_share
                 .sum().sort_values(ascending=False))
trade_summary.iloc[:50].plot.bar(figsize=(14, 6),
                                 color='darkblue',
                                 title='Share of Traded Value')
f = lambda y, _: '{:.0%}'.format(y)
plt.gca().yaxis.set_major_formatter(FuncFormatter(f)) 
```

*图 2.1*显示了结果图：

![](img/B15439_02_01.png)

图 2.1：50 种交易量最大的证券的交易价值份额

### 如何重建所有交易和订单簿

解析的消息允许我们重建给定日期的订单流。`'R'`消息类型包含给定日期内交易的所有股票的列表，包括**首次公开发行**（**IPO**）和交易限制的信息。

在一天中，新订单会被添加，执行和取消的订单会从订单簿中删除。对于参考先前日期下的订单的消息，正确的会计处理需要在多天内跟踪订单簿。

`get_messages()`功能说明了如何收集影响交易的单个股票的订单。（有关每条消息的详细信息，请参阅 ITCH 规范。）代码稍微简化；更多详细信息，请参阅笔记本`rebuild_nasdaq_order_book.ipynb`：

```py
def get_messages(date, stock=stock):
    """Collect trading messages for given stock"""
    with pd.HDFStore(itch_store) as store:
        stock_locate = store.select('R', where='stock = 
                                     stock').stock_locate.iloc[0]
        target = 'stock_locate = stock_locate'
        data = {}
        # relevant message types
        messages = ['A', 'F', 'E', 'C', 'X', 'D', 'U', 'P', 'Q']
        for m in messages:
            data[m] = store.select(m,  
              where=target).drop('stock_locate', axis=1).assign(type=m)
    order_cols = ['order_reference_number', 'buy_sell_indicator', 
                  'shares', 'price']
    orders = pd.concat([data['A'], data['F']], sort=False,  
                        ignore_index=True).loc[:, order_cols]
    for m in messages[2: -3]:
        data[m] = data[m].merge(orders, how='left')
    data['U'] = data['U'].merge(orders, how='left',
                                right_on='order_reference_number',
                                left_on='original_order_reference_number',
                                suffixes=['', '_replaced'])
    data['Q'].rename(columns={'cross_price': 'price'}, inplace=True)
    data['X']['shares'] = data['X']['cancelled_shares']
    data['X'] = data['X'].dropna(subset=['price'])
    data = pd.concat([data[m] for m in messages], ignore_index=True, 
                      sort=False) 
```

重建成功交易，即执行的订单与从交易相关消息类型`C`、`E`、`P`和`Q`取消的订单相对简单：

```py
def get_trades(m):
    """Combine C, E, P and Q messages into trading records"""
    trade_dict = {'executed_shares': 'shares', 'execution_price': 'price'}
    cols = ['timestamp', 'executed_shares']
    trades = pd.concat([m.loc[m.type == 'E',
                              cols + ['price']].rename(columns=trade_dict),
                        m.loc[m.type == 'C',
                              cols + ['execution_price']]
                        .rename(columns=trade_dict),
                        m.loc[m.type == 'P', ['timestamp', 'price',
                                              'shares']],
                        m.loc[m.type == 'Q',
                              ['timestamp', 'price', 'shares']]
                        .assign(cross=1), ],
                       sort=False).dropna(subset=['price']).fillna(0)
    return trades.set_index('timestamp').sort_index().astype(int) 
```

订单簿跟踪限额订单，买卖订单的各种价格水平构成订单簿的深度。重建给定深度级别的订单簿需要以下步骤：

`add_orders()`功能将给定时间戳的升序卖出订单和降序买入订单累加到所需的深度：

```py
def add_orders(orders, buysell, nlevels):
    new_order = []
    items = sorted(orders.copy().items())
    if buysell == 1:
        items = reversed(items)  
    for i, (p, s) in enumerate(items, 1):
        new_order.append((p, s))
        if i == nlevels:
            break
    return orders, new_order 
```

我们迭代所有瘙痒消息，并按照规范要求处理订单及其替代品：

```py
for message in messages.itertuples():
    i = message[0]
    if np.isnan(message.buy_sell_indicator):
        continue
    message_counter.update(message.type)
    buysell = message.buy_sell_indicator
    price, shares = None, None
    if message.type in ['A', 'F', 'U']:
        price, shares = int(message.price), int(message.shares)
        current_orders[buysell].update({price: shares})
        current_orders[buysell], new_order = 
          add_orders(current_orders[buysell], buysell, nlevels)
        order_book[buysell][message.timestamp] = new_order
    if message.type in ['E', 'C', 'X', 'D', 'U']:
        if message.type == 'U':
            if not np.isnan(message.shares_replaced):
                price = int(message.price_replaced)
                shares = -int(message.shares_replaced)
        else:
            if not np.isnan(message.price):
                price = int(message.price)
                shares = -int(message.shares)
        if price is not None:
            current_orders[buysell].update({price: shares})
            if current_orders[buysell][price] <= 0:
                current_orders[buysell].pop(price)
            current_orders[buysell], new_order = 
              add_orders(current_orders[buysell], buysell, nlevels)
            order_book[buysell][message.timestamp] = new_order 
```

*图 2.2*突出显示了流动性在任何给定时间点的深度，使用不同的强度来可视化不同价格水平下的订单数量。左面板显示了限制订单价格的分布如何加权到较高价格的购买订单。

右面板描绘了整个交易日内限价指令和价格的演变：黑线跟踪市场时段内执行交易的价格，而红点和蓝点表示每分钟的单个限价指令（有关详细信息，请参阅笔记本）：

![](img/B15439_02_02.png)

图 2.2：根据订单簿的 AAPL 市场流动性

## 从刻度到条形–如何规范市场数据

交易数据以纳秒为单位编制索引，以不规则的间隔到达，并且非常嘈杂。例如，**买入-卖出反弹**导致当交易开始在买入和卖出市场指令之间交替时，价格在买入和卖出价格之间波动。为了提高噪声信号比率和价格序列的统计特性，我们需要通过聚集交易活动对滴答数据进行重新采样和规范化。

我们通常收集累计期间的**开盘（第一）、高点、低点和收盘（最后）价格和成交量**（合称**OHLCV**），以及**成交量加权平均价格**（**VWAP**）和与数据相关的时间戳。

有关更多详细信息，请参阅 GitHub 上本章文件夹中的`normalize_tick_data.ipynb`笔记本。

### 原材料-勾选条

以下代码生成 AAPL 的原始交易价格和交易量数据图：

```py
stock, date = 'AAPL', '20191030'
title = '{} | {}'.format(stock, pd.to_datetime(date).date()
with pd.HDFStore(itch_store) as store:
    sys_events = store['S'].set_index('event_code') # system events
    sys_events.timestamp = sys_events.timestamp.add(pd.to_datetime(date)).dt.time
    market_open = sys_events.loc['Q', 'timestamp'] 
    market_close = sys_events.loc['M', 'timestamp']
with pd.HDFStore(stock_store) as store:
    trades = store['{}/trades'.format(stock)].reset_index()
trades = trades[trades.cross == 0] # excluding data from open/close crossings
trades.price = trades.price.mul(1e-4) # format price
trades = trades[trades.cross == 0]    # exclude crossing trades
trades = trades.between_time(market_open, market_close) # market hours only
tick_bars = trades.set_index('timestamp')
tick_bars.index = tick_bars.index.time
tick_bars.price.plot(figsize=(10, 5), title=title), lw=1) 
```

*图 2.3*显示结果图：

![](img/B15439_02_03.png)

图 2.3：勾线

从`scipy.stats.normaltest`的低 p 值可以看出，滴答声收益率远远不是正态分布：

```py
from scipy.stats import normaltest
normaltest(tick_bars.price.pct_change().dropna())
NormaltestResult(statistic=62408.76562431228, pvalue=0.0) 
```

### 普通去噪-时间条

时间条涉及按时段的交易聚合。以下代码获取时间条的数据：

```py
def get_bar_stats(agg_trades):
    vwap = agg_trades.apply(lambda x: np.average(x.price, 
           weights=x.shares)).to_frame('vwap')
    ohlc = agg_trades.price.ohlc()
    vol = agg_trades.shares.sum().to_frame('vol')
    txn = agg_trades.shares.size().to_frame('txn')
    return pd.concat([ohlc, vwap, vol, txn], axis=1)
resampled = trades.groupby(pd.Grouper(freq='1Min'))
time_bars = get_bar_stats(resampled) 
```

我们可以将结果显示为价格量图表：

```py
def price_volume(df, price='vwap', vol='vol', suptitle=title, fname=None):
    fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(15, 8))
    axes[0].plot(df.index, df[price])
    axes[1].bar(df.index, df[vol], width=1 / (len(df.index)), 
                color='r')
    xfmt = mpl.dates.DateFormatter('%H:%M')
    axes[1].xaxis.set_major_locator(mpl.dates.HourLocator(interval=3))
    axes[1].xaxis.set_major_formatter(xfmt)
    axes[1].get_xaxis().set_tick_params(which='major', pad=25)
    axes[0].set_title('Price', fontsize=14)
    axes[1].set_title('Volume', fontsize=14)
    fig.autofmt_xdate()
    fig.suptitle(suptitle)
    fig.tight_layout()
    plt.subplots_adjust(top=0.9)
price_volume(time_bars) 
```

上述代码生成*图 2.4*：

![](img/B15439_02_04.png)

图 2.4：时间条

或者，我们可以使用Bokeh 绘图库将数据表示为烛台图：

```py
resampled = trades.groupby(pd.Grouper(freq='5Min')) # 5 Min bars for better print
df = get_bar_stats(resampled)
increase = df.close > df.open
decrease = df.open > df.close
w = 2.5 * 60 * 1000 # 2.5 min in ms
WIDGETS = "pan, wheel_zoom, box_zoom, reset, save"
p = figure(x_axis_type='datetime', tools=WIDGETS, plot_width=1500, 
          title = "AAPL Candlestick")
p.xaxis.major_label_orientation = pi/4
p.grid.grid_line_alpha=0.4
p.segment(df.index, df.high, df.index, df.low, color="black")
p.vbar(df.index[increase], w, df.open[increase], df.close[increase], 
       fill_color="#D5E1DD", line_color="black")
p.vbar(df.index[decrease], w, df.open[decrease], df.close[decrease], 
       fill_color="#F2583E", line_color="black")
show(p) 
```

由此产生*图 2.5*中的曲线图：

![](img/B15439_02_05.png)

图 2.5:Bokeh 烛台图

### 订单碎片核算-卷栏

时间条平滑了原始刻度数据中包含的一些噪音，但可能无法解释订单的碎片。以执行为中心的算法交易可能旨在匹配给定期间内的**成交量加权平均价格**（**VWAP**。这将把单个订单分成多个交易，并根据历史模式下订单。即使市场上没有新的信息，时间条对同一订单的处理方式也会有所不同。

成交量条提供了一种根据成交量汇总交易数据的替代方法。我们可以通过以下方式实现这一点：

```py
min_per_trading_day = 60 * 7.5
trades_per_min = trades.shares.sum() / min_per_trading_day
trades['cumul_vol'] = trades.shares.cumsum()
df = trades.reset_index()
by_vol = (df.groupby(df.cumul_vol.
                     div(trades_per_min)
                     .round().astype(int)))
vol_bars = pd.concat([by_vol.timestamp.last().to_frame('timestamp'),
                      get_bar_stats(by_vol)], axis=1)
price_volume(vol_bars.set_index('timestamp')) 
```

我们在*图 2.6*中得到上述代码的曲线图：

![](img/B15439_02_06.png)

图 2.6：音量条

### 价格变动会计-美元条形图

当资产价格发生重大变化时，或股票分割后，一定数量的股票价值发生变化。成交量条不能正确反映这一点，并且会妨碍对反映此类变化的不同时期的交易行为进行比较。在这些情况下，应调整音量条法，以利用股票和价格的乘积生产美元条。

以下代码显示美元条形图的计算：

```py
value_per_min = trades.shares.mul(trades.price).sum()/(60*7.5) # min per trading day
trades['cumul_val'] = trades.shares.mul(trades.price).cumsum()
df = trades.reset_index()
by_value = df.groupby(df.cumul_val.div(value_per_min).round().astype(int))
dollar_bars = pd.concat([by_value.timestamp.last().to_frame('timestamp'), get_bar_stats(by_value)], axis=1)
price_volume(dollar_bars.set_index('timestamp'), 
             suptitle=f'Dollar Bars | {stock} | {pd.to_datetime(date).date()}') 
```

由于价格在一天中一直相当稳定，因此该图与音量条非常相似：

![](img/B15439_02_07.png)

图 2.7：美元条形图

## AlgoSeek 分钟栏–股票报价和交易数据

AlgoSeek提供了以前仅向机构投资者提供的质量的历史日内数据。AlgoSeek 股票栏以用户友好的格式提供非常详细的日内报价和交易数据，旨在简化日内 ML 驱动策略的设计和回溯测试。正如我们将看到的，数据不仅包括 OHLCV 信息，还包括买卖价差信息以及价格上涨和下跌的滴答数等信息。

AlgoSeek 非常友好地提供了 2013-2017 年纳斯达克 100 种股票的分钟条形数据样本，以供演示，并将向本书读者提供该数据的子集。

在本节中，我们将介绍可用的交易和报价信息，并说明如何处理原始数据。在后面的章节中，我们将演示如何将这些数据用于 ML 驱动的日内策略。

### 从合并进料到分棒

AlgoSeek 分条基于**证券信息处理器**（**SIP**提供的数据，该处理器管理本节开头提到的合并提要。您可以在[查看文档 https://www.algoseek.com/samples/](https://www.algoseek.com/samples/) 。

SIP 汇总每个交易所的最佳出价和报价，以及由此产生的交易和价格。法律禁止交易所在将报价和交易发送给 SIP 之前将其发送给 direct Feed。鉴于美国股票交易的分散性，综合提要提供了一个方便的市场现状快照。

更重要的是，SIP 作为监管机构根据Reg NMS 确定**国家最佳出价和报价**（**NBBO**）的基准。OHLC 酒吧报价基于 NBBO，每个出价或要价报价均指 NBBO 价格。

每家交易所都会公布其最高账面价格以及该价格下的可用股票数量。当发布的报价改善了 NBBO 时，NBBO 发生变化。买卖报价持续存在，直到由于交易、价格上涨或取消最新买卖而发生变化。虽然历史 OHLC 条形图通常基于条形图期间的交易，但 NBBO 买卖报价可能会从以前的条形图结转，直到出现新的 NBBO 事件。

AlgoSeek 酒吧涵盖整个交易日，从第一个交易所开盘到最后一个交易所收盘。正常营业时间以外的酒吧通常活动有限。东部时间的交易时间为：

*   上市前：约 04:00:00（因交易所而异）至 09:29:59
*   市场：09:30:00 至 16:00:00
*   延长时间：16:00:01 至 20:00:00

### 报价和交易数据字段

分条数据最多包含 54 个字段。条的**打开**、**高**、**低**和**关闭**元素有八个字段，分别为：

*   酒吧和相应交易的时间戳
*   现行买卖报价和相关交易的价格和规模

还有 14 个数据点具有棒周期的**音量信息**：

*   股票数量和相应的交易
*   位于或低于投标价、投标报价与中点之间、中点处、中点与报价之间、位于或高于报价的交易量，以及交叉交易量
*   上涨或下跌时交易的股票数量，即价格上涨或下跌时，以及价格没有变化时，由之前的价格运动方向区分

AlgoSeek 数据还包含向 FINRA 报告并在经纪自营商、暗池或 OTC 内部处理的股票**数量。这些交易代表的是隐藏的交易量，或者在事后才公开的交易量。**

最后，数据包括酒吧期间的**成交量加权平均价格**（**VWAP**）和最小和最大买卖价差。

### 如何处理日内数据

在本节中，我们将处理AlgoSeek 样本数据。GitHub 上的`data`目录包含如何从 AlgoSeek 下载数据的说明。

分钟栏数据有四种版本：有或没有报价信息，有或没有 FINRA 的报告量。每天有一个压缩文件夹，每个股票代码包含一个 CSV 文件。

以下代码示例将仅交易分钟条数据提取到每日`.parquet`文件中：

```py
directories = [Path(d) for d in ['1min_trades']]
target = directory / 'parquet'
for zipped_file in directory.glob('*/**/*.zip'):
    fname = zipped_file.stem
    print('\t', fname)
    zf = ZipFile(zipped_file)
    files = zf.namelist()
    data = (pd.concat([pd.read_csv(zf.open(f),
                                   parse_dates=[['Date',
                                                 'TimeBarStart']])
                       for f in files],
                      ignore_index=True)
            .rename(columns=lambda x: x.lower())
            .rename(columns={'date_timebarstart': 'date_time'})
            .set_index(['ticker', 'date_time']))
    data.to_parquet(target / (fname + '.parquet')) 
```

我们可以将`parquet`文件组合到一块 HDF5 存储器中，如下所示，产生 5380 万条记录，消耗 3.2 GB 内存，覆盖 5 年和 100 种股票：

```py
path = Path('1min_trades/parquet')
df = pd.concat([pd.read_parquet(f) for f in path.glob('*.parquet')]).dropna(how='all', axis=1)
df.columns = ['open', 'high', 'low', 'close', 'trades', 'volume', 'vwap']
df.to_hdf('data.h5', '1min_trades')
print(df.info(null_counts=True))
MultiIndex: 53864194 entries, (AAL, 2014-12-22 07:05:00) to (YHOO, 2017-06-16 19:59:00)
Data columns (total 7 columns):
open      53864194 non-null float64
high      53864194 non-null float64
Low       53864194 non-null float64
close     53864194 non-null float64
trades    53864194 non-null int64
volume    53864194 non-null int64
vwap      53852029 non-null float64 
```

我们可以使用`plotly`快速创建一个交互式烛台图，用于在浏览器中查看一天的 AAPL 数据：

```py
idx = pd.IndexSlice
with pd.HDFStore('data.h5') as store:
    print(store.info())
    df = (store['1min_trades']
          .loc[idx['AAPL', '2017-12-29'], :]
          .reset_index())
fig = go.Figure(data=go.Ohlc(x=df.date_time,
                             open=df.open,
                             high=df.high,
                             low=df.low,
                             close=df.close)) 
```

*图 2.8*显示了生成的静态图像：

![](img/B15439_02_08.png)

图 2.8：绘制烛台图

AlgoSeek 还提供调整因子，以纠正股票分割、股息和其他公司行为的定价和交易量。

# API 获取市场数据

有几个选项可以使用 Python 通过 API 访问市场数据。我们将首先介绍一些内置于 pandas 图书馆中的资源和`yfinance`工具，该工具有助于从雅虎下载日终市场数据和最新基础数据！资金

然后，我们将简要介绍交易平台 Quantopian、数据提供商 Quandl 和本书后面将使用的 Zipline 回溯测试库，并列出访问各种类型市场数据的几个附加选项。GitHub 上的目录`data_providers`包含几个说明这些选项用法的笔记本。

## 使用 pandas 进行远程数据访问

熊猫库允许使用`read_html`功能访问网站上显示的数据，并通过相关的`pandas-datareader`库访问各种数据提供商的 API 端点。

### 阅读 HTML 表格

从维基百科下载一个或多个HTML 表的内容，如 S&P500 索引的组成部分，工作如下：

```py
sp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
sp = pd.read_html(sp_url, header=0)[0] # returns a list for each table
sp.info()
RangeIndex: 505 entries, 0 to 504
Data columns (total 9 columns):
Symbol                    505 non-null object
Security                  505 non-null object
SEC filings                505 non-null object
GICS Sector               505 non-null object
GICS Sub Industry         505 non-null object
Headquarters Location     505 non-null object
Date first added           408 non-null object
CIK                       505 non-null int64
Founded                   234 non-null object 
```

### 熊猫市场数据阅读器

pandas 用于直接方便访问数据提供程序 API，但此功能已转移到`pandas-datareader`库（有关文档链接，请参阅`README`。

API 的稳定性随提供商策略的不同而变化，并在不断变化。有关最新信息，请参阅文档。截至 2019 年 12 月，版本为 0.8.1 的以下来源可用：

<colgroup><col> <col> <col></colgroup> 
| 来源 | 范围 | 议论 |
| 蒂因戈 | 股票、共同基金和 ETF 的历史日终价格。 | 免费注册 API 密钥。免费帐户只能访问 500 个符号。 |
| 投资者交易所（IEX） | 如果在 IEX 上交易，历史股价可用。 | 需要来自 IEX 云控制台的 API 密钥。 |
| 阿尔法优势 | 每日、每周和每月频率、20 多年以及过去 3-5 天的日内数据的历史股票数据。它还拥有外汇和行业业绩数据。 |  |
| 昆德尔 | 网站上列出的免费数据源。 |  |
| 法玛/法语 | 风险因子投资组合回报。 | 用于*第 7 章*、*线性模型——从风险因子到回报预测*。 |
| TSP 基金数据 | 共同基金价格。 |  |
| 纳斯达克 | 交易股票的最新元数据。 |  |
| Stooq 索引数据 | 由于许可证问题，一些股票指数无法从其他地方获得。 |  |
| 莫克斯 | 莫斯科交换历史数据。 |  |

数据的访问和检索遵循类似的 API，适用于所有源，如 Yahoo！金融：

```py
import pandas_datareader.data as web
from datetime import datetime
start = '2014'              # accepts strings
end = datetime(2017, 5, 24) # or datetime objects
yahoo= web.DataReader('FB', 'yahoo', start=start, end=end)
yahoo.info()
DatetimeIndex: 856 entries, 2014-01-02 to 2017-05-25
Data columns (total 6 columns):
High         856 non-null float64
Low          856 non-null float64
Open         856 non-null float64
Close        856 non-null float64
Volume       856 non-null int64
Adj Close    856 non-null float64
dtypes: float64(5), int64(1) 
```

## yfinance–从雅虎抓取数据！资金

`yfinance`旨在提供一种可靠、快速的方式从雅虎下载历史市场数据！资金图书馆原名为`fix-yahoo-finance`。这个库的使用非常简单；笔记本`yfinance_demo`展示了图书馆的功能。

### 如何下载日终和日内价格

`Ticker`对象允许下载从雅虎网站抓取的各种数据点：

```py
import yfinance as yf
symbol = 'MSFT'
ticker = yf.Ticker(symbol) 
```

`.history`方法获得不同时期的历史价格，从一天到最大可用时间，以及不同的频率，而日内价格仅适用于最后几天。要以一分钟的频率下载调整后的 OHLCV 数据和公司行动，请使用：

```py
data = ticker.history(period='5d',
                      interval='1m',
                      actions=True,
                      auto_adjust=True)
data.info()
DatetimeIndex: 1747 entries, 2019-11-22 09:30:00-05:00 to 2019-11-29 13:00:00-05:00
Data columns (total 7 columns):
Open            1747 non-null float64
High            1747 non-null float64
Low             1747 non-null float64
Close           1747 non-null float64
Volume          1747 non-null int64
Dividends       1747 non-null int64
Stock Splits    1747 non-null int64 
```

该笔记本还说明了如何访问季度和年度金融报表、可持续性得分、分析师建议和即将发布的收益日期。

### 如何下载期权链和价格

`yfinance`还提供对各种合同的期权到期日期和价格等信息的访问。使用上一个示例中的`ticker`实例，我们使用以下方法获取到期日期：

```py
ticker.options
('2019-12-05',  '2019-12-12',  '2019-12-19',..) 
```

对于其中任何一个日期，我们都可以访问期权链并查看各种看跌/看涨合同的详细信息，如下所示：

```py
options = ticker.option_chain('2019-12-05')
options.calls.info()
Data columns (total 14 columns):
contractSymbol       35 non-null object
lastTradeDate        35 non-null datetime64[ns]
strike               35 non-null float64
lastPrice            35 non-null float64
bid                  35 non-null float64
ask                  35 non-null float64
change               35 non-null float64
percentChange        35 non-null float64
volume               34 non-null float64
openInterest         35 non-null int64
impliedVolatility    35 non-null float64
inTheMoney           35 non-null bool
contractSize         35 non-null object
currency             35 non-null object 
```

该库还允许使用代理服务器来防止速率限制，并促进多个股票的批量下载。笔记本还演示了这些功能的使用。

## 全域

Quantopian 是一家投资公司，为众源交易算法提供研究平台。注册是免费的，会员可以使用各种各样的数据来源研究交易想法。它还提供了一个根据历史数据对算法进行回溯测试的环境，以及使用实时数据对其进行样本外前向测试的环境。它对表现最好的算法进行投资分配，这些算法的作者有权获得 10%的利润份额（在撰写本文时）。

Quantopian 研究平台由 Jupyter 笔记本电脑环境组成，用于阿尔法因子研究和性能分析的研发。还有一个**交互式开发环境**（**IDE**），用于对算法策略进行编码，并使用自 2002 年以来的历史数据对结果进行回溯测试（以分钟条频率）。

用户还可以用实时数据模拟算法，即称为*纸面交易*。Quantopian 提供各种市场数据集，包括一分钟频率的美国股票和期货价格和交易量数据，以及美国股票公司基本面数据，它还集成了许多备选数据集。

我们将在*第 4 章**金融特征工程*中更详细地探讨量子平台——如何研究阿尔法因子*，并在整本书中依赖其功能，因此请随时开户。（有关更多详细信息，请参阅 GitHub 存储库。）*

## 拉链

Zipline 是算法交易库，为 Quantopian 回溯测试和实时交易平台提供动力。在将结果移植到在线 Quantopian 平台进行纸面和现场交易之前，还可以离线使用有限数量的免费数据包制定策略，这些数据包可以被接收并用于测试交易想法的性能。

Zipline 需要自定义环境查看笔记本开头的说明`zipline_data_demo.ipynb`以下代码说明了 Zipline 如何允许我们访问一系列公司的每日股票数据。您可以在 Jupyter 笔记本中使用同名的神奇功能运行 Zipline 脚本。

首先，需要使用所需的安全符号初始化上下文。我们还将使用一个计数器变量。然后，Zipline 调用`handle_data`，我们使用`data.history()`方法回顾单个时段，并将最后一天的数据附加到`.csv`文件中：

```py
%load_ext zipline
%%zipline --start 2010-1-1 --end 2018-1-1 --data-frequency daily
from zipline.api import order_target, record, symbol
def initialize(context):
    context.i = 0
    context.assets = [symbol('FB'), symbol('GOOG'), symbol('AMZN')]

def handle_data(context, data):
    df = data.history(context.assets, fields=['price', 'volume'], 
                      bar_count=1, frequency="1d")
    df = df.to_frame().reset_index()

    if context.i == 0:
        df.columns = ['date', 'asset', 'price', 'volume']
        df.to_csv('stock_data.csv', index=False)
    else:
        df.to_csv('stock_data.csv', index=False, mode='a', header=None)
    context.i += 1
df = pd.read_csv('stock_data.csv')
df.date = pd.to_datetime(df.date)
df.set_index('date').groupby('asset').price.plot(lw=2, legend=True, 
       figsize=(14, 6)); 
```

对于前面的代码，我们得到下面的图：

![](img/B15439_02_09.png)

图 2.9：拉链线数据访问

在接下来的章节中，我们将更详细地探讨 Zipline 的功能，尤其是在线 Quantopian 平台。

## 昆德尔

Quandl 使用 Python API 提供了广泛的数据源，包括免费数据源和订阅数据源。注册并获得免费的 API 密钥，每天进行 50 次以上的调用。Quandl 数据涵盖股票以外的多种资产类别，包括外汇、固定收益、指数、期货和期权以及商品。

API 的使用是直接的、文档化的和灵活的，除了单系列下载之外，还有许多方法，例如，包括批量下载或元数据搜索。

根据美国能源部的报价，以下电话获取 1986 年以后的石油价格：

```py
import quandl
oil = quandl.get('EIA/PET_RWTC_D').squeeze()
oil.plot(lw=2, title='WTI Crude Oil Price') 
```

我们得到了上述代码的图：

![](img/B15439_02_10.png)

图 2.10:Quandl 石油价格示例

## 其他市场数据提供商

各种各样的提供商提供各种资产类别的市场数据。相关类别的例子包括：

*   交易所收入中越来越多的份额来自越来越广泛的数据服务，通常使用订阅。
*   彭博社和汤森路透长期以来一直是领先的数据聚合商，在 285 亿美元的金融数据市场上的总份额超过 55%。FactSet 等较小的竞争对手正在成长或崛起，如 money.net、Quandl、Trading Economics 和 Barchart。
*   专业数据提供商比比皆是。LOBSTER 就是一个例子，它实时聚合纳斯达克订单数据。
*   免费数据提供商包括 Alpha Vantage，它为实时股票、外汇和加密货币市场数据以及技术指标提供 Python API。
*   除 Quantopian 外，提供数据访问研究平台的众包投资公司还包括 2018 年 3 月成立的阿尔法交易实验室，该实验室提供 HFT 基础设施和数据。

# 如何使用基础数据

基础数据与决定证券价值的经济驱动因子有关。数据的性质取决于资产类别：

*   对于股票和企业信贷，它包括企业金融数据，以及行业和经济数据。
*   对于政府债券，它包括国际宏观数据和外汇。
*   对于大宗商品，它包括特定于资产的供给和需求决定因子，如农作物的天气数据。

我们将重点关注美国的股票基本面，那里的数据更容易获取。全世界大约有 13000 多家上市公司发布了 200 万页的年度报告和超过 30000 小时的盈利电话。在算法交易中，基础数据和根据该数据设计的特征可用于直接导出交易信号，例如作为价值指标，并且是预测模型（包括 ML 模型）的基本输入。

## 金融报表数据

证券交易委员会（SEC）要求美国发行人，即上市公司和证券，包括共同基金，除其他各种监管备案要求外，还需提交三份季度金融报表（表 10-Q）和一份年度报告（表 10-K）。

自 20 世纪 90 年代初以来，SEC 通过其**电子数据收集、分析和检索**（**埃德加**系统提供这些文件。它们构成权益和其他证券（如公司信贷）基本分析的主要数据源，其价值取决于发行人的业务前景和金融状况。

### 自动处理–XBRL

自从美国证券交易委员会推出了**XBRL**以来，监管文件的自动分析变得容易多了，这是一种免费、开放的全球标准，用于商业报告的电子表示和交换。XBRL 是基于 XML 的；它依赖于定义报表元素含义的分类法，并映射到在电子版报表中突出显示相应信息的标记。其中一种分类法代表美国**公认会计原则**（**GAAP**）。

SEC 在 2005 年针对会计丑闻引入了自愿 XBRL 申报，然后在 2009 年要求所有申报人采用这种格式，并继续将强制覆盖范围扩大到其他监管申报。美国证券交易委员会（SEC）维护着一个网站，该网站列出了塑造不同文件内容的当前分类法，并可用于提取特定项目。

以下数据集以扁平化数据格式提供从提交给委员会的 EX-101 附件中提取的信息，以帮助用户使用数据进行分析。数据反映了从 XBRL 标记的金融报表中选择的信息。目前包括季度和年度金融报表的数字数据，以及某些附加字段，例如**标准行业分类**（**SIC**）。

有几种途径可以跟踪和访问向 SEC 报告的基本数据：

*   作为 EDGAR**公共传播服务**（**PDS**的的一部分，可免费获得接受文件的电子提要。
*   SEC 每 10 分钟更新一次 RSS 提要，其中列出了结构化披露提交。
*   有公共索引文件，用于通过 FTP 检索所有文件，以实现自动处理。
*   金融报表（和附注）数据集包含来自所有金融报表和随附附注的解析 XBRL 数据。

SEC 还通过 SEC.gov 发布包含 EDGAR 文件互联网搜索流量的日志文件，尽管延迟了六个月。

### 构建基础数据时间序列

金融报表和附注数据集中的数据范围包括从主要金融报表（资产负债表、损益表、现金流量、权益变动和综合收益）中提取的数字数据以及这些报表上的脚注。现有数据最早来自 2009 年。

#### 提取金融报表和附注数据集

以下代码下载并提取**金融报表和附注**（**FSN**数据集中包含的给定季度范围内的所有历史文件（更多详细信息，请参阅`edgar_xbrl.ipynb`）：

```py
SEC_URL = 'https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/'
first_year, this_year, this_quarter = 2014, 2018, 3
past_years = range(2014, this_year)
filing_periods = [(y, q) for y in past_years for q in range(1, 5)]
filing_periods.extend([(this_year, q) for q in range(1, this_quarter + 
                                                    1)])
for i, (yr, qtr) in enumerate(filing_periods, 1):
    filing = f'{yr}q{qtr}_notes.zip'
    path = data_path / f'{yr}_{qtr}' / 'source'
    response = requests.get(SEC_URL + filing).content
    with ZipFile(BytesIO(response)) as zip_file:
        for file in zip_file.namelist():
            local_file = path / file
            with local_file.open('wb') as output:
                for line in zip_file.open(file).readlines():
                    output.write(line) 
```

数据相当大，为了能够比原始文本文件允许的速度更快地访问，最好将文本文件转换为二进制拼花柱状格式（请参阅*熊猫高效数据存储*本章后面部分将介绍与数据帧兼容的各种数据存储选项的性能比较：

```py
for f in data_path.glob('**/*.tsv'):
    file_name = f.stem  + '.parquet'
    path = Path(f.parents[1]) / 'parquet'
    df = pd.read_csv(f, sep='\t', encoding='latin1', low_memory=False)
    df.to_parquet(path / file_name) 
```

对于每个季度，FSN 数据被组织成八个文件集，其中包含有关提交、编号、分类标签、表示等信息。每个数据集由行和字段组成，并作为制表符分隔的文本文件提供：

<colgroup><col> <col> <col></colgroup> 
| 文件 | 数据集 | 描述 |
| `SUB` | 屈服 | 按公司、表格、日期等标识每个 XBRL 提交 |
| `TAG` | 标签 | 定义并解释每个分类标记 |
| `DIM` | 维 | 向数字和纯文本数据添加详细信息 |
| `NUM` | 数字的 | 归档中每个不同数据点对应一行 |
| `TXT` | 纯文本 | 包含所有非数字 XBRL 字段 |
| `REN` | 翻译 | 用于在 SEC 网站上呈现的信息 |
| `PRE` | 演示 | 主语句中的标记和编号表示的详细信息 |
| `CAL` | 计算 | 显示标记之间的算术关系 |

#### 检索所有季度苹果文件

提交数据集包含检索文件所需的唯一标识符：**中央索引键**（**CIK**）和**登录号**（**adsh**）。以下显示了苹果公司 2018 年第 1 季度 10-Q 申报的部分信息：

```py
apple = sub[sub.name == 'APPLE INC'].T.dropna().squeeze()
key_cols = ['name', 'adsh', 'cik', 'name', 'sic', 'countryba',  
            'stprba', 'cityba', 'zipba', 'bas1', 'form', 'period', 
            'fy', 'fp', 'filed']
apple.loc[key_cols]
name                    APPLE INC
adsh                    0000320193-18-000070
cik                     320193
name                    APPLE INC
sic                     3571
countryba               US
stprba                  CA
cityba                  CUPERTINO
zipba                   95014
bas1                    ONE APPLE PARK WAY
form                    10-Q
period                  20180331
fy                      2018
fp                      Q2
filed                   20180502 
```

使用 CIK，我们可以识别苹果所有可用的历史季度申报，并结合这些信息获得 26 份 10-Q 表格和 9 份年度 10-K 表格：

```py
aapl_subs = pd.DataFrame()
for sub in data_path.glob('**/sub.parquet'):
    sub = pd.read_parquet(sub)
    aapl_sub = sub[(sub.cik.astype(int) == apple.cik) & 
                   (sub.form.isin(['10-Q', '10-K']))]
    aapl_subs = pd.concat([aapl_subs, aapl_sub])
aapl_subs.form.value_counts()
10-Q    15
10-K     4 
```

有了每个文件的登录号，我们现在可以依靠分类法从`NUM`和`TXT`文件中选择适当的 XBRL 标签（列在`TAG`文件中），以获得感兴趣的数字或文本/脚注数据点。

首先，让我们从 19 份苹果文件中提取所有可用的数字数据：

```py
aapl_nums = pd.DataFrame()
for num in data_path.glob('**/num.parquet'):
    num = pd.read_parquet(num).drop('dimh', axis=1)
    aapl_num = num[num.adsh.isin(aapl_subs.adsh)]
    aapl_nums = pd.concat([aapl_nums, aapl_num])
aapl_nums.ddate = pd.to_datetime(aapl_nums.ddate, format='%Y%m%d')
aapl_nums.shape
(28281, 16) 
```

#### 构建价格/收益时间序列

总共，9 年的归档历史为我们提供了 28000 多个数值。我们可以选择一个有用的字段，例如**稀释每股收益**（**每股收益**），我们可以结合市场数据来计算流行的**市盈率**（**市盈率**的估值比率。

然而，我们确实需要考虑到苹果在 2014 年 6 月 4 日以 7:1 的比例拆分其股票，并调整拆分前的每股收益值，以使收益与价格数据相当，而价格数据以*调整*的形式解释了这些变化。以下代码块显示了如何调整收益数据：

```py
field = 'EarningsPerShareDiluted'
stock_split = 7
split_date = pd.to_datetime('20140604')
# Filter by tag; keep only values measuring 1 quarter
eps = aapl_nums[(aapl_nums.tag == 'EarningsPerShareDiluted')
                & (aapl_nums.qtrs == 1)].drop('tag', axis=1)
# Keep only most recent data point from each filing
eps = eps.groupby('adsh').apply(lambda x: x.nlargest(n=1, columns=['ddate']))
# Adjust earnings prior to stock split downward
eps.loc[eps.ddate < split_date,'value'] = eps.loc[eps.ddate < 
        split_date, 'value'].div(7)
eps = eps[['ddate', 'value']].set_index('ddate').squeeze()
# create trailing 12-months eps from quarterly data
eps = eps.rolling(4, min_periods=4).sum().dropna() 
```

我们可以使用Quandl 获取苹果 2009 年以来的股价数据：

```py
import pandas_datareader.data as web
symbol = 'AAPL.US'
aapl_stock = web.DataReader(symbol, 'quandl', start=eps.index.min())
aapl_stock = aapl_stock.resample('D').last() # ensure dates align with 
                                               eps data 
```

现在，我们有数据来计算整个时期的 12 个月后市盈率：

```py
pe = aapl_stock.AdjClose.to_frame('price').join(eps.to_frame('eps'))
pe = pe.fillna(method='ffill').dropna()
pe['P/E Ratio'] = pe.price.div(pe.eps)
axes = pe.plot(subplots=True, figsize=(16,8), legend=False, lw=2); 
```

我们从前面的代码中得到以下曲线图：

![](img/B15439_02_11.png)

图 2.11:EDGAR 文件的后续市盈率

## 其他基本数据来源

基础数据还有许多其他来源。使用前面介绍的`pandas_datareader`模块可以访问许多。其他数据可直接从某些组织获得，如国际货币基金组织、世界银行或世界各地的主要国家统计机构（请参阅 GitHub 上的*参考文献*部分）。

### 熊猫数据阅读器–宏观和行业数据

`pandas-datareader`库根据前一节市场数据末尾介绍的约定，方便访问。它涵盖了许多全球基本宏观和行业数据源的 API，包括：

*   Kenneth French 的数据库：投资组合的市场数据，获取关键风险因子（如规模、价值和动量因子）的回报，按行业分类（参见*第 4 章*、*金融特征工程——如何研究阿尔法因子*）
*   圣路易斯联邦储备银行（FRED）：美联储关于美国经济和金融市场的数据
*   世界银行：长期、低频率经济和社会发展及人口统计全球数据库
*   经合组织：类似于世界银行对经合组织国家的数据
*   谜：各种数据集，包括其他来源
*   欧盟统计局：以欧盟为重点的经济、社会和人口数据

# 利用 pandas 实现高效数据存储

在本书中，我们将使用许多不同的数据集，在效率和性能方面比较主要的格式是值得的。特别是，我们将比较以下内容：

*   **CSV**：逗号分隔，标准平面文本文件格式。
*   **HDF5**：分层数据格式，最初由国家超级计算应用中心开发。它是一种快速、可扩展的数字数据存储格式，可在 pandas 中使用 PyTables 库获得。
*   **拼花**：ApacheHadoop 生态系统的一部分，一种提供高效数据压缩和编码的二进制柱状存储格式，由 Cloudera 和 Twitter 开发。熊猫可以通过《熊猫》的原始作者韦斯·麦金尼（Wes McKinney）领导的 pyarrow 图书馆获得。

`storage_benchmark.ipynb`笔记本使用可配置为包含数字或文本数据或两者的测试数据框来比较前面库的性能。对于 HDF5 库，我们测试了固定格式和表格式。表格格式允许查询，并且可以附加到。

以下图表说明了 100000 行的读写性能，其中 1000 列为随机浮点，1000 列为随机 10 个字符字符串，或者只有 2000 列（以对数为单位）：

![](img/B15439_02_12.png)

图 2.12：存储基准

左面板显示，对于纯数字数据，HDF5 格式的性能最好，而表格格式与 CSV 共享最小的内存占用，为 1.6 GB。`fixed`格式使用两倍的空间，`parquet`格式使用 2GB。

对于数字和文本数据的混合，拼花地板是读写操作的最佳选择。相对于 CSV 而言，HDF5 在*读取*时具有优势，但在*写入*时则较慢，因为它会对文本数据进行 pickle 处理。

本笔记本演示了如何使用`%%timeit`cell magic 配置、测试和收集计时，同时演示了使用这些存储格式所需的相关命令的使用。

# 总结

本章介绍了构成大多数交易策略支柱的市场和基础数据来源。您了解了访问这些数据的各种方法，以及如何预处理原始信息，以便您可以开始使用我们不久将介绍的 ML 技术提取交易信号。

在下一章中，在继续讨论交易策略的设计和评估以及 ML 模型的使用之前，我们需要涵盖近年来出现的备选数据集，这些数据集是算法交易 ML 流行的重要驱动因子。