# 十五、主题建模——总结财经新闻

在最后一章中，我们使用**字袋**（**弓**模型）将非结构化文本数据转换为数字格式。该模型从词序中提取，并将文档表示为词向量，其中每个条目表示标记与文档的相关性。生成的**文档术语矩阵**（**DTM**）或作为术语文档矩阵转置，可用于根据文档的标记内容相互比较文档或查询向量的相似性，从而找到大海捞针。它提供信息丰富的功能来对文档进行分类，例如在我们的情感分析示例中。

然而，这个文档模型产生高维数据和非常稀疏的数据，但它对总结内容或更接近理解内容几乎没有作用。在本章中，我们将使用**无监督机器学习**使用**主题建模**从文档中提取隐藏主题。这些主题可以自动生成对大量文档的详细见解。为了理解 haystack 本身并允许我们根据文档与各种主题的关联性来标记文档，它们非常有用。

**主题模型**生成复杂、可解释的文本特征，这是从大量文档集合中提取交易信号的第一步。它们加快了文档的审阅速度，帮助识别和聚类类似文档，并支持预测建模。

Apple T0.应用程序 T1T.包括在公司披露或盈利电话记录、客户评论或合同中潜在的有洞察力的主题的无监督发现。此外，文档主题关联通过分配（例如）情感度量或更直接地分配后续相关资产回报来促进标记。

更具体地说，阅读本章后，您将了解：

*   主题建模是如何发展的，它实现了什么，以及为什么它很重要
*   使用**潜在语义索引**（**LSI**降低 DTM 的维度）
*   **概率潜在语义分析**（**pLSA**的主题抽取
*   **潜在 Dirichlet 分配**（**LDA**如何改进 pLSA 成为最流行的话题模型
*   可视化和评估主题建模结果
*   使用 sklearn 和 Gensim 运行 LDA
*   如何将主题建模应用于收益电话和财经新闻文章集合

您可以在 GitHub 存储库的相应目录中找到本章的代码示例以及指向其他资源的链接。笔记本电脑包括图像的彩色版本。

# 学习潜在主题–目标和方法

主题建模发现隐藏的主题，这些主题捕获文档体中单个单词之外的语义信息。它旨在解决机器学习算法的一个关键挑战，该算法通过超越“实际编写的内容”的词汇级别到“预期内容”的语义级别，从文本数据中学习。由此产生的主题可用于根据文档与各种主题的关联对文档进行注释。

实际上，主题模型会自动**汇总大量文档**，以便于组织和管理以及搜索和推荐。同时，它使人们能够理解文档，从而理解主题的描述。

主题模型也减轻了经常困扰弓模型的维度诅咒；用高维稀疏向量表示文档会使相似性度量产生噪声，导致距离度量不准确，并导致文本分类模型的过度拟合。

此外，BOW 模型由于忽略了词序而丢失了上下文和语义信息。它也无法捕捉同义词（多个词具有相同的含义）或多义词（一个词具有多个含义）。后一种方法的结果是，文档检索或相似性搜索可能会忽略文档未按用于搜索或比较的术语编制索引这一点。

BOW 模型的这些缺点引发了一个问题：我们如何从数据中学习有意义的主题，从而促进与文献数据的更有效的交互？

主题模型最初尝试改进向量空间模型（在 20 世纪 70 年代中期开发），应用线性代数降低 DTM 的维数。这种方法类似于我们在*第 13 章*、*数据驱动风险因子和无监督学习的资产配置*中讨论的主成分分析算法。虽然有效，但如果没有基准模型，很难评估这些模型的结果。在响应中，出现了概率模型，该模型假设了一个明确的文档生成过程，并提供了算法来对该过程进行反向工程并恢复底层主题。

下表突出显示了模型演变中的关键里程碑，我们将在以下章节中更详细地介绍这些里程碑：

<colgroup><col> <col> <col></colgroup> 
| 模型 | 年 | 描述 |
| **潜在语义索引（LSI）** | 1988 | 通过降低单词空间的维数来捕获语义文档术语关系 |
| **概率潜在语义分析（pLSA）** | 1999 | 逆向工程是一个生成过程，假设单词生成一个主题，文档作为主题的组合 |
| **潜在狄氏分配（LDA）** | 2003 | 为文档添加生成过程：三级分层贝叶斯模型 |

潜在语义索引

**潜在语义索引**（**LSI**）——也称**潜在语义分析**（**LSA**）——旨在改善省略包含查询术语同义词的相关文档的查询结果（Dumais 等人，1988）。其目标是对文档和术语之间的关系进行建模，以便预测术语应与文档相关联，尽管由于单词使用的可变性，没有观察到这种关联。

LSI 使用线性代数通过分解 DTM 找到给定数量的*k*潜在主题。更具体地说，它使用**奇异值分解**（**SVD**）使用*k*奇异值和向量来寻找最佳低秩 DTM 近似。换句话说，LSI 建立在我们在*第 13 章*、*数据驱动风险因子和无监督学习的资产配置*中遇到的一些降维技术的基础上。作者还尝试了分层聚类，但发现它对此目的限制太多。

在此上下文中，SVD 识别一组不相关的索引变量或因子，这些变量或因子通过因子值向量表示每个术语和文档。*图 15.1*说明了 SVD 如何将 DTM 分解为三个矩阵：两个包含正交奇异向量的矩阵和一个包含奇异值（用作比例因子）的对角矩阵。

假设输入 DTM 中存在某种相关性，奇异值的值会衰减。因此，选择*T*-最大的奇异值可以得到原始 DTM 的低维近似值，该近似值丢失的信息相对较少。在压缩版本中，有*N*项的行或列只有*T*<*N*项。

DTM 的 LSI 分解如*图 15.1*所示：

*   第一个![](img/B15439_15_001.png)矩阵表示文档和主题之间的关系。
*   对角线矩阵根据主题的语料库强度对主题进行缩放。
*   第三个矩阵为术语主题关系建模。

![](img/B15439_15_01.png)

图 15.1：LSI 和 SVD

将前两个矩阵![](img/B15439_15_002.png)相乘产生的矩阵行对应于投射到潜在主题空间的原始文档的位置。

## 如何使用 sklearn 实现 LSI

我们将使用上一章中介绍的 BBC 文章数据来说明 LSI，因为它们足够小，可以进行快速培训，并允许我们将主题分配与类别标签进行比较。更多实施细节请参见笔记本`latent_semantic_indexing`。

我们首先加载文档并创建一个包含 50 篇文章的训练和（分层）测试集。然后，我们使用`TfidfVectorizer`对数据进行矢量化，以获得加权 DTM 计数，并过滤掉出现在少于 1%或超过 25%的文档中的单词，以及通用停止词，以获得约 2900 个单词的词汇表：

```py
vectorizer = TfidfVectorizer(max_df=.25, min_df=.01, 
                             stop_words='english', 
                             binary=False)
train_dtm = vectorizer.fit_transform(train_docs.article)
test_dtm = vectorizer.transform(test_docs.article) 
```

我们使用 scikit learn 的`TruncatedSVD`类，该类仅计算*k*最大奇异值，以降低 DTM 的维数。确定性`arpack`算法提供精确的解决方案，但默认的“随机化”实现对于大型矩阵更有效。

我们计算了五个主题以匹配五个类别，这仅解释了总 DTM 方差的 5.4%，因此更多的主题是合理的：

```py
svd = TruncatedSVD(n_components=5, n_iter=5, random_state=42)
svd.fit(train_dtm)
svd.explained_variance_ratio_.sum()
0.05382357286057269 
```

LSI 为 DTM 确定了一个新的正交基础，该基础将等级降低到所需主题的数量。经过训练的`svd`对象的`.transform()`方法将文档投射到新的主题空间。该空间源于文档向量的降维，对应于本节前面说明的![](img/B15439_15_002.png)转换：

```py
train_doc_topics = svd.transform(train_dtm)
train_doc_topics.shape
(2175, 5) 
```

我们可以对一篇文章进行取样，以查看其在主题空间中的位置。我们画了一篇与主题 1 和主题 2 最（积极）相关的“政治”文章：

```py
i = randint(0, len(train_docs))
train_docs.iloc[i, :2].append(pd.Series(doc_topics[i], index=topic_labels))
Category                                     Politics
Heading     What the election should really be about?
Topic 1                                          0.33
Topic 2                                          0.18
Topic 3                                          0.12
Topic 4                                          0.02
Topic 5                                          0.06 
```

本样本的主题分配与*图 15.2*所示的每个类别的平均主题权重一致（“政治”是最右边的条）。它们说明了 LSI 如何将*k*主题表示为*k*维空间中的方向（笔记本包括每个类别的平均主题分配投影到二维空间）。

每个类别都有明确的定义，测试任务与列车任务相匹配。然而，权重既有正面的，也有负面的，这使得解释主题更加困难。

![A screenshot of a video game  Description automatically generated](img/B15439_15_02.png)

图 15.2：列车和测试数据的 LSI 主题权重

我们还可以显示与每个主题最密切相关的单词（绝对值）。主题似乎捕捉了一些语义信息，但没有明确区分（参见*图 15.3*。

![](img/B15439_15_03.png)

图 15.3：每个 LSI 主题的前 10 个单词

## 优势和局限性

LSI 的优势包括消除噪声和减轻维数灾难。它还捕获一些语义方面，如同义词，并通过主题关联对文档和术语进行聚类。此外，它不需要文档语言的知识，信息检索查询和文档比较都很容易做到。

然而，LSI 的结果很难解释，因为主题是带有正负条目的词向量。此外，在选择要使用的维度或主题的数量时，没有允许评估适合性或提供指导的基础模型。

# 概率潜在语义分析

**概率潜在语义分析**（**pLSA**从**统计角度**研究 LSI/LSA，并创建生成模型，以解决 LSA 缺乏理论基础的问题（Hofmann 2001）。

如 DTM 所述，pLSA 将出现在文件*d*中的概率词*w*明确建模为涉及主题*t*的条件独立多项式分布的混合物。

word 文档共现的发生方式既有**对称公式，也有**不对称公式。前者假设单词和文档都是由潜在主题类生成的。相反，非对称模型假设在给定文档的情况下选择主题，在给定主题的情况下，单词会导致第二步。

![](img/B15439_15_004.png)

主题数量是在培训前选择的一个**超参数**，不从数据中学习。

*图 15.4*中的**图版符号**描述了概率模型中的统计相关性。更具体地说，它编码了刚才为不对称模型描述的关系。每个矩形代表多个项目：外部块代表*M*文档，而内部阴影矩形代表每个文档的*N*字。我们只遵守文件及其内容；该模型推断出隐藏或潜在的主题分布：

![](img/B15439_15_04.png)

图 15.4：板表示法中 pLSA 建模的统计相关性

现在让我们看看如何在实践中实现这个模型。

## 如何使用 sklearn 实现 pLSA

pLSA 相当于使用 Kullback-Leibler 散度目标的**非负矩阵分解**（**NMF**）（查看 GitHub 上的参考文献）。因此，我们可以使用`sklearn.decomposition.NMF`类按照 LSI 示例实现该模型。

使用`TfidfVectorizer`生产的 DTM 的相同列车测试分割，我们将 pLSA 装配如下：

```py
nmf = NMF(n_components=n_components, 
          random_state=42, 
          solver='mu',
          beta_loss='kullback-leibler', 
          max_iter=1000)
nmf.fit(train_dtm) 
```

我们得到了重建误差的一个度量，它可以替代先前的解释方差度量：

```py
nmf.reconstruction_err_
316.2609400385988 
```

由于其概率性质，pLSA 只产生正面的主题权重，从而为测试和训练集产生更直接的主题类别关系，如*图 15.5*所示：

![](img/B15439_15_05.png)

图 15.5：列车和试验数据的 pLSA 重量（按主题）

我们还注意到，描述每个主题的单词列表开始变得更有意义；例如，“娱乐”类别与主题 4 最直接相关，包括“电影”、“明星”等，如图 15.6 所示：

![](img/B15439_15_06.png)

图 15.6:pLSA 每个主题的热门词汇

## 优势和局限性

使用概率模型的好处是，我们现在可以通过评估不同模型分配给新文档的概率来比较不同模型的性能，给定训练期间学习的参数。这也意味着结果具有明确的概率解释。此外，pLSA 捕获了更多的语义信息，包括多义词。

另一方面，与 LSI 相比，pLSA 增加了计算复杂度，并且该算法可能只产生局部最大值，而不是全局最大值。最后，它不会生成新文档的生成模型，因为它将它们视为给定的。

# 潜在 Dirichlet 分配

**潜在 Dirichlet 分配**（**LDA**）通过增加主题的生成过程来扩展 pLSA（Blei、Ng 和 Jordan，2003）。它是最流行的主题模型，因为它倾向于产生人类可以关联的有意义的主题，可以将主题分配给新文档，并且是可扩展的。LDA 模型的变体可以包括元数据，如作者或图像数据，或者学习层次主题。

## LDA 的工作原理

LDA是一个**层次贝叶斯模型**，其中假设主题是单词上的概率分布，文档是主题上的分布。更具体地说，该模型假设主题遵循稀疏的 Dirichlet 分布，这意味着文档只反映一小部分主题，而主题通常只使用有限数量的术语。

### Dirichlet 分布

Dirichlet 分布产生的概率向量可用作离散概率分布。也就是说，它随机生成给定数量的值，这些值为正数，总和为一。它有一个正实值的参数![](img/B15439_15_005.png)，控制概率的集中。接近于零的值意味着只有少数值为正，并接收大部分概率质量。*图 15.7*显示了![](img/B15439_15_006.png)=0.1 的三张尺寸为 10 的图纸：

![](img/B15439_15_07.png)

图 15.7:Dirichlet 分布的三个图

笔记本`dirichlet_distribution`包含一个模拟，可以让你用不同的参数值进行实验。

### 生成模型

LDA 主题模型假设当作者向文档体添加文章时，会有以下生成过程：

1.  随机混合一小部分主题，比例由狄里克莱概率定义。
2.  对于文本中的每个单词，根据文档主题概率选择一个主题。
3.  根据主题词概率从主题词列表中选择一个词。

因此，文章内容取决于每个主题的权重和构成每个主题的术语。Dirichlet 分布控制文档主题和主题词的选择。它编码了这样一种想法，即文档只涉及几个主题，而每个主题只频繁使用少量单词。

*图 15.8*中 LDA 模型的**铭牌符号**总结了这些关系，并强调了关键模型参数：

![](img/B15439_15_08.png)

图 15.8：板表示法中 LDA 模型的统计相关性

### 过程的逆向工程

生成过程显然是虚构的，但事实证明是有用的，因为它允许恢复各种分布。LDA 算法对虚构作者的工作进行反向工程，并得出文档主题词关系的摘要，简要描述：

*   每个主题对文档的贡献百分比
*   每个单词与主题的概率关联

LDA 通过逆向工程假定的内容生成过程，解决了**贝叶斯推理**问题，即从文档体及其包含的单词中恢复分布。Blei et al.（2003）的原始论文使用**变分贝叶斯**（**VB**来近似后验分布。替代方案包括吉布斯抽样和期望传播。我们将很快说明 sklearn 和 Gensim 库的实现。

## 如何评估 LDA 主题

无监督的主题模型不能保证结果是有意义的或可解释的，并且没有客观的指标来评估监督学习中结果的质量。人类主题评估被认为是黄金标准，但它可能很昂贵，而且不容易大规模提供。

更客观地评估结果的两个选项包括**困惑**，该选项在未看到的文档上评估模型，以及**主题一致性**指标，该指标旨在评估未发现模式的语义质量。

### 困惑

当将困惑应用于 LDA 时，测量通过模型恢复的主题词概率分布预测不可见文本文档样本的程度。它基于此分布*p*的熵*H*（*p*，并针对令牌集*w*计算：

![](img/B15439_15_007.png)

接近于零的度量意味着分布更适合预测样本。

### 话题连贯

主题连贯性衡量主题模型结果的语义一致性，即人类是否会认为与主题相关的单词及其概率有意义。

为此，它通过测量与主题最相关的单词之间的语义相似度来为每个主题打分。更具体地说，连贯性度量是基于观察定义主题的一组单词*W*的概率。

有两种为 LDA 设计的一致性度量，显示与人类对主题质量的判断一致，即麻省大学和 UCI 度量。

UCI 度量（Stevens et al.2012）将一个词对的得分定义为两个不同的（顶部）主题词对*w*i、*w*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="Subscript--PACKT-">j</sub>![](img/B15439_15_008.png)【T14 w 之间的**逐点互信息**（**PMI**）之和以及平滑因子![](img/B15439_15_009.png)：

![](img/B15439_15_010.png)

概率是从外部语料库（如 Wikipedia）上滑动窗口中的单词共现频率计算出来的，因此可以将此度量视为与语义基本事实的外部比较。

相比之下，麻省理工大学的指标（Mimno 等人，2011 年）使用训练语料库中大量文档*D*中的共现来计算连贯性得分：

![](img/B15439_15_011.png)

与将模型结果与外在的基本事实进行比较不同，该度量反映了内在的一致性。对这两项措施进行了评估，以使其与人类的判断保持一致（Röder，Duth 和 Hinneburg，2015）。在这两种情况下，接近零的值意味着一个主题更加连贯。

## 如何使用 sklearn 实现 LDA

我们将像以前一样使用 BBC 数据并使用 sklearn 的`decomposition.LatentDirichletAllocation`课程培训一个 LDA 模型，共有五个主题（有关参数的详细信息，请参阅 sklearn 文档，有关实施细节，请参阅笔记本`lda_with_sklearn`：

```py
lda_opt = LatentDirichletAllocation(n_components=5, 
                                    n_jobs=-1, 
                                    max_iter=500,
                                    learning_method='batch', 
                                    evaluate_every=5,
                                    verbose=1, 
                                    random_state=42)
ldat.fit(train_dtm)
LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,
             evaluate_every=5, learning_decay=0.7, learning_method='batch',
             learning_offset=10.0, max_doc_update_iter=100, max_iter=500,
             mean_change_tol=0.001, n_components=5, n_jobs=-1,
             n_topics=None, perp_tol=0.1, random_state=42,
             topic_word_prior=None, total_samples=1000000.0, verbose=1) 
```

该模型在训练过程中跟踪样本内的困惑，并在该度量停止改进时停止迭代。我们可以使用 sklearn 对象像往常一样持久化并加载结果：

```py
joblib.dump(lda, model_path / 'lda_opt.pkl')
lda_opt = joblib.load(model_path / 'lda_opt.pkl') 
```

## 如何使用 pyLDAvis 可视化 LDA 结果

主题可视化有助于使用人类判断评估主题质量。pyLDAvis 是 LDAvis 的 Python端口，在 R 和`D3.js`中开发（Sievert 和 Shirley 2014）。我们将介绍关键概念；每个 LDA 应用程序笔记本都包含示例。

pyLDAvis 显示了主题之间的全局关系，同时还通过检查与每个主题最密切相关的术语，以及与每个术语相关的主题，促进了它们的语义评估。它还解决了一个挑战，即在语料库中经常出现的术语往往比定义主题的词在分布中占主导地位。

为此，LDAVis 将术语*w*的**相关性***r*引入主题*t*。相关性通过计算两个指标的加权平均值，按主题对术语进行灵活排序：

*   主题*t*与术语*w*的关联程度，表示为条件概率*p*（*w**t*）
*   显著性，或称提升，它测量主题 t*p*（*w**t*）的术语*w*的频率与所有文档*p*（*w*的总体频率相比如何

更具体地说，我们可以计算给定用户定义权重![](img/B15439_15_012.png)的术语*w*和主题*t*的相关性*r*，如下所示：

![](img/B15439_15_013.png)

该工具允许用户交互更改![](img/B15439_15_014.png)以调整相关性，从而更新术语的排名。用户研究发现![](img/B15439_15_015.png)可以产生最合理的结果。

## 如何使用 Gensim 实现 LDA

Gensim 是一个专门的**自然语言处理**（**NLP**）库，具有快速 LDA 实现和许多附加功能。我们也将在下一章的文字向量中使用它（参见笔记本`lda_with_gensim`了解详细信息和安装目录了解相关说明）。

我们将 sklearn 的`CountVectorizer`或`TfIdfVectorizer`生成的 DTM 转换为 Gensim 数据结构，如下所示：

```py
train_corpus = Sparse2Corpus(train_dtm, documents_columns=False)
test_corpus = Sparse2Corpus(test_dtm, documents_columns=False)
id2word = pd.Series(vectorizer.get_feature_names()).to_dict() 
```

Gensim 的 LDA 算法包括多种设置：

```py
LdaModel(corpus=None, 
       num_topics=100, 
       id2word=None, 
       distributed=False, 
       chunksize=2000,  # No of doc per training chunk.
       passes=1,        # No of passes through corpus during training
       update_every=1,  # No of docs to be iterated through per update
       alpha='symmetric', 
       eta=None,        # a-priori belief on word probability
       decay=0.5,      # % of lambda forgotten when new doc is examined
       offset=1.0,     # controls slow down of first few iterations.
       eval_every=10,  # how often estimate log perplexity (costly)
       iterations=50,  # Max. of iterations through the corpus
       gamma_threshold=0.001, # Min. change in gamma to continue
       minimum_probability=0.01, # Filter topics with lower probability
       random_state=None, 
       ns_conf=None, 
       minimum_phi_value=0.01, # lower bound on term probabilities
       per_word_topics=False,  #  Compute most word-topic probabilities
       callbacks=None, 
       dtype=<class 'numpy.float32'>) 
```

Gensim 还为并行训练提供了一个`LdaMulticore`模型，该模型可以使用 Python 的并行计算多处理特性来加速训练。

模型培训只需要实例化`LdaModel`，如下：

```py
lda_gensim = LdaModel(corpus=train_corpus,
                      num_topics=5,
                      id2word=id2word) 
```

Gensim 评估主题连贯性，如前一节所述，并显示每个主题最重要的单词：

```py
coherence = lda_gensim.top_topics(corpus=train_corpus, coherence='u_mass') 
```

我们可以将结果显示为如下：

```py
topic_coherence = []
topic_words = pd.DataFrame()
for t in range(len(coherence)):
    label = topic_labels[t]
    topic_coherence.append(coherence[t][1])
    df = pd.DataFrame(coherence[t][0], columns=[(label, 'prob'),
                                                (label, 'term')])
    df[(label, 'prob')] = df[(label, 'prob')].apply(
                              lambda x: '{:.2%}'.format(x))
    topic_words = pd.concat([topic_words, df], axis=1)

topic_words.columns = pd.MultiIndex.from_tuples(topic_words.columns)
pd.set_option('expand_frame_repr', False)
print(topic_words.head()) 
```

这显示了每个主题的以下关键词：

<colgroup><col> <col> <col> <col> <col> <col> <col> <col> <col> <col></colgroup> 
| 专题 1 | 专题 2 | 专题 3 | 专题 4 | 专题 5 |
| 可能性 | 学期 | 可能性 | 学期 | 可能性 | 学期 | 可能性 | 学期 | 可能性 | 学期 |
| 0.55% | 在线 的 | 0.90% | 最好的 | 1.04% | 可移动的 | 0.64% | 集市 | 0.94% | 劳动 |
| 0.51% | 地点 | 0.87% | 游戏 | 0.98% | 电话 | 0.53% | 发育 | 0.72% | 布莱尔 |
| 0.46% | 游戏 | 0.62% | 玩 | 0.51% | 音乐 | 0.52% | 出售 | 0.72% | 棕色的 |
| 0.45% | 网 | 0.61% | 赢了 | 0.48% | 电影 | 0.49% | 经济 | 0.65% | 选举 |
| 0.44% | 习惯于 | 0.56% | 赢 | 0.48% | 使用 | 0.45% | 价格 | 0.57% | 统一的 |

*图 15.9*的左面板显示了主题连贯性得分，突出了主题质量的衰退（至少部分是由于数据集相对较小）：

![](img/B15439_15_09.png)

图 15.9：主题连贯性和测试集分配

右侧面板显示了对我们的测试集（50 篇文章）的评估以及我们训练过的模型。该模型犯了四个错误，准确率为 92%。

# 收益调用中讨论的建模主题

在第 3 章，第 1 章，第 2 章，金融备选数据——类别和用例 AUTT3，我们学习了如何从 SewitkAlga 站点中提取收益调用数据。在本节中，我们将使用此源代码演示主题建模。我用的是 2018 到 2019 年间的 700 个财报电话会议记录。这是一个相当小的数据集；对于实际应用，我们需要一个更大的数据集。

目录`earnings_calls`包含几个文件，其中包含本节中使用的代码示例。有关加载、探索和预处理数据以及训练和评估单个模型的详细信息，请参阅笔记本`lda_earnings_calls`和`run_experiments.py`文件，以了解下一步描述的实验。

## 数据预处理

成绩单包括公司代表、运营商的个人陈述，以及与分析师的问答。我们将这些语句视为单独的文档，忽略运算符语句，以获得 32047 项，平均字数和中值字数分别为 137 和 62：

```py
documents = []
for transcript in earnings_path.iterdir():
    content = pd.read_csv(transcript / 'content.csv')
    documents.extend(content.loc[(content.speaker!='Operator') & (content.content.str.len() > 5), 'content'].tolist())
len(documents)
32047 
```

我们使用 spaCy 对这些文档进行预处理，如*第 13 章*、*数据驱动的风险因子和资产配置与无监督学习*（参考笔记本）所示，并将清理和整理后的文本存储为新的文本文件。

如*图 15.10*所示，对最常见的代币的研究揭示了我们在第二步中删除的特定于域的停止词，如“年”和“季度”，我们还过滤掉少于 10 个单词的语句，以便保留大约 22582 个。

![](img/B15439_15_10.png)

图 15.10：最常见的财报电话会议代币

## 模型培训和评估

为了举例说明，我们创建了一个 DTM，其中包含 0.5%到 25%的文档中出现的术语，从而产生了 1529 个特征。现在我们继续训练 15 个主题模型，在语料库中使用 25 次传递。在 4 核 i7 上这需要两分钟多一点的时间。

如*图 15.11*所示，每个主题的前 10 个单词确定了几个不同的主题，从明显的金融信息到临床试验（主题 5）、中国和关税问题（主题 9）以及技术问题（主题 11）。

![](img/B15439_15_11.png)

图 15.11：财报电话会议主题

使用 pyLDAvis 的相关性指标，无条件频率相对于提升的权重为 0.6，主题定义变得更加直观，如关于中国和贸易战的主题 7 的*图 15.12*所示：

![](img/B15439_15_12.png)

图 15.12:pyLDAVis 的交互式主题浏览器

该笔记本还说明了如何通过主题关联查找文档。在这种情况下，分析员可以查看相关陈述的细微差别，使用情感分析进一步处理特定主题的文本数据，或者指定从市场价格衍生的标签。

## 运行实验

为了说明不同参数设置的影响，我们针对不同的 DTM约束和模型参数运行了数百个实验。更具体地说，`min_df`和`max_df`参数的范围分别为 50-500 个字和 10%到 100%的文档，或者使用二进制计数和绝对计数。然后，我们用 3 到 50 个主题训练 LDA 模型，在语料库中使用 1 次和 25 次。

*图 15.13*中的图表说明了主题连贯性（越高越好）和困惑（越低越好）的结果。25-30 个话题后连贯性下降，困惑感也同样增加。

![](img/B15439_15_13.png)

图 15.13:LDA 超参数设置对主题质量的影响

笔记本包括回归结果，这些结果量化了参数和结果之间的关系。我们通常使用绝对计数和较小的词汇量来获得更好的结果。

# 财经新闻的话题建模

笔记本`lda_financial_news`包含一个 LDA 示例，应用于 2018 年前五个月超过 306000 篇财经新闻文章的子集。数据集已发布在 Kaggle 上，文章来源于 CNBC、路透社、华尔街日报等。该笔记本包含下载说明。

我们根据其章节标题选择了最相关的 120000 篇文章，总计 5400 万个标记，平均每篇文章 429 个单词。为了准备 LDA 模型的数据，我们依靠 spaCy 删除数字和标点符号，并将结果进行线性化。

*图 15.14*突出显示了剩余最频繁的代币和文章长度分布，中间长度为 231 个代币；第 90 百分位是 642 个单词。

![](img/B15439_15_14.png)

图 15.14：财经新闻数据的语料库统计

在*图 15.15*中，我们展示了一个模型的结果，该模型使用了 3570 个基于`min_df`=0.005 和`max_df`=0.1 的词汇表，并使用单次通过，以避免 15 个主题的长时间训练。我们可以使用经过训练的`LdaModel`的`top_topics`属性来获取每个主题最可能的单词（有关详细信息，请参阅笔记本）。

![](img/B15439_15_15.png)

图 15.15：财经新闻主题的前 15 个单词

这些主题概述了与该时期相关的几个问题，包括英国脱欧（主题 8）、朝鲜（主题 4）和特斯拉（主题 14）。

Gensim 提供了一个`LdaMultiCore`实现，该实现允许使用 Python 的多处理模块进行并行培训，并在使用四个工人时将性能提高 50%。不过，由于 I/O 瓶颈，更多的员工不会进一步减少培训时间。

# 总结

在本章中，我们探讨了主题建模的使用，以深入了解大量文档的内容。我们讨论了潜在语义索引，它使用 DTM 的降维将文档投影到潜在主题空间。虽然它能有效地解决高维词向量造成的维度灾难，但它并没有捕获太多语义信息。概率模型对文档、主题和单词的相互作用做出明确的假设，允许算法对文档生成过程进行逆向工程，并评估模型是否适合新文档。我们了解到，LDA 能够提取合理的主题，使我们能够以自动化的方式获得对大量文本的高层次理解，同时以有针对性的方式识别相关文档。

在下一章中，我们将学习如何训练将单个单词嵌入高维向量空间的神经网络，该空间捕获重要的语义信息，并允许我们使用生成的单词向量作为高质量的文本特征。